<!DOCTYPE html>
<html>
<head>
  <title>Reducing a model to get confidence intervals</title>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="" />
  <meta name="author" content="">
  <link rel="shortcut icon" href="assets/img/07-10-06_2241.jpg">
  <link rel="alternate" type="application/rss+xml" href="">
  <link href="../libraries/frameworks/purus/css/bootstrap.min.css" rel="stylesheet" />
  <link href="../libraries/frameworks/purus/css/bootstrap-responsive.min.css" rel="stylesheet" />
  <link href="../libraries/frameworks/purus/css/main.css" rel="stylesheet" />
  <link href="../libraries/highlighters/prettify/css/twitter-bootstrap.css" rel="stylesheet">
  <!-- IE6-8 support of HTML5 elements -->
  <!--[if lt IE 9]>
    <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
  <![endif]-->
  <link href='http://fonts.googleapis.com/css?family=Raleway:400,600,200,800' rel='stylesheet' type='text/css'>
  <link href='http://fonts.googleapis.com/css?family=Open+Sans' rel='stylesheet' type='text/css'>
  <link href='http://fonts.googleapis.com/css?family=Droid+Sans' rel='stylesheet' type='text/css'>
  <script src="http://ajax.googleapis.com/ajax/libs/jquery/1.8.3/jquery.min.js"></script>
    <style>
  	#disqus_thread {
		margin-top: 140px;
	}
	  #sidebar .sidebar-nav .info h3 a:hover, a:hover { color: #01A9DB; }
	  #sidebar .sidebar-nav #avatar img, #sidebar .sidebar-nav ul#links li.active a { border-color: #01A9DB; }
	  #sidebar .sidebar-nav ul#links li a:hover { background: #01A9DB; }
    p {text-align: justify;}
  </style>
  <link rel="stylesheet" href = "../assets/css/box_with_title.css">
<link rel="stylesheet" href = "../assets/css/custom.css">
<link rel="stylesheet" href = "../assets/css/ribbons.css">

</head>
<body>
	<div class="container-fluid">
		<div class="row-fluid">
			<div id="sidebar" class="span2">
			  <div class="sidebar-nav sidebar-nav-fixed">
				  <div class="info">
				    <p id="avatar"><a href="#"><img alt="Title" src="http://stla.github.com/stlapblog/assets/img/07-10-06_2241.jpg " style="width:250px" /></a></p>
				    <h3><a href="/">stlaPblog </a></h3>
					  <p class="description">a blog about Mathematics, R, Statistics, ...</p>
					</div>
					<ul id="links">
			        <li><a href="http://stla.github.com/stlapblog/index.html">Home</a></li>
        <li><a href="http://stla.github.com/stlapblog/about.html">About</a></li>
      
				  <br/>
				  <div style="padding-left: 5px;">
					<h3>Some links</h3>
					<h4>&#9654 R links</h4>
						<div style="padding-left: 5px;">
					    <ul>
					      <li><a href="http://github.com/ramnathv/poirot/"><u>Poirot</u></a>Reproducible Blogging with R Markdown</li>
			          <li><a href="http://slidify.org/"><u>Slidify</u></a>Reproducible html5 slides from R markdown</li>
			          <li><a href="http://www.r-bloggers.com/"><u>R-bloggers</u></a>Blog posts about R, contributed by R bloggers worldwide.</li>
					    </ul>
				    </div>
			    <br/>
			  	<h4>&#9654 Blogs</h4>
						<div style="padding-left: 5px;">
					    <ul>
					      <li><a href="http://stla.overblog.com/"><u>stla.overblog</u></a>My previous blog</li>
			          <li><a href="http://timelyportfolio.blogspot.be/"><u>Timely Portfolio</u>
			</a>A great blog about R, Javascript, and more</li>
					    </ul>
				    </div>
					</div>
			    </ul>
				</div>
			</div>
						<div id="content" class='span10'>
				<div id="post-wrapper">
          <ol id="posts">
            <li class="post">
              <h3>
                <a href="#">Reducing a model to get confidence intervals</a>
              </h3>
              <span>2014-04-12</span><br/>
               <a class='label label-success' href='https://raw.github.com/stla/stlapblog/gh-pages/posts/ModelReduction.Rmd'>Source</a>
              <div class='lead'>

<h2>Reducing the one-way ANOVA model with random effects</h2>

<p>Consider the balanced one-way ANOVA model with random effects, call \(\cal M\) 
this model:
\[({\cal M})\colon \qquad \begin{cases}
 (y_{ij} \mid \mu_i) \sim_{\text{iid}} {\cal N}(\mu_i, \sigma^2_w) & j=1,\ldots,J \\ 
\mu_i \sim_{\text{iid}} {\cal N}(\mu, \sigma^2_b) & i=1,\ldots,I
\end{cases}.\]
Let us derive the distribution of the observed group means \(\bar{y}_{i\bullet}\):
\[(\bar{y}_{i\bullet} \mid \mu_i) \sim {\cal N}\left(\mu_i, \frac{\sigma^2_w}{J}\right)\] 
for every \(i=1,\ldots,I\), and finally 
\[\bar{y}_{i\bullet}\sim_{\text{iid}} {\cal N}\left(\mu, \sigma^2_b+\frac{\sigma^2_w}{J}\right) \qquad i=1,\ldots,I.\]</p>

<p>Denote \(z_i=\bar{y}_{i\bullet}\) for more clarity. Thus \({(z_i)}_{i=1}^I\) is a sample 
of <em>iid</em> Gaussian distributions:
\[({\cal M}')\colon \qquad
z_i \sim_{\text{iid}} {\cal N}\left(\mu, \delta^2\right), \quad i=1,\ldots,I\] 
with \(\delta^2=\sigma^2_b+\frac{\sigma^2_w}{J}\). </p>

<p>Thus, we have a new model \({\cal M}'\) derived from \(\cal M\) and for which there is 
a well-known \(100(1-\alpha)\%\)-confidence interval around \(\mu\):
\[\bar{z}_{\bullet} \pm t^*_{I-1}(\alpha/2)\frac{SS(z)}{(I-1)I}\]
where \(SS(z)=\sum_{i=1}^I{(z_i-\bar{z}_{\bullet})}^2\) is the total variation 
of the \(z_i\). 
Compare this confidence interval to the one derived at 
the end of my article about 
<a href="http://stla.github.io/stlapblog/posts/Anova1random.html">the balanced one-way ANOVA model with random effects</a>: <em>they are exactly the same !</em> </p>

<p>Thus, there&#39;s no lost of information about \(\mu\) when we observe only 
the group means \(\bar{y}_{i\bullet}\).</p>

<h2>General principle of model reduction</h2>

<p>Was the previous remark an expected one ? 
Given the original model \(\cal M\) with observations \(y=(y_{ij})\), the reduced 
model \({\cal M}'\) has been derived by considering the \(z_i:=f_i(y)\) as the 
observations for some functions \(f_i\). 
The parameter \(\mu\) appears in both models. </p>

<p>The obvious thing is that any  \(100(1-\alpha)\%\)-confidence interval 
about \(\mu\) in the reduced model \({\cal M}'\) also is a 
\(100(1-\alpha)\%\)-confidence interval 
about \(\mu\) in the original model \(\cal M\). 
But generally such a method will not provide an <em>optimal</em> confidence interval 
(in a sense to be made precise), as shown by the following other example</p>

<h2>Reducing the two-ways ANOVA model without interaction</h2>

<p>Consider the fixed effects two-ways ANOVA model 
with replications but without interaction :
\[({\cal M})\colon \qquad
y_{ijk} \sim {\cal N}(\mu+\alpha_i+\beta_j, \sigma^2), 
\qquad i=1,\ldots,I, \quad j=1,\ldots,J, \quad k=1,\ldots,K,\]
with \(\sum \alpha_i=\sum \beta_j=0\) and 
assuming as usual independent observations \(y_{ijk}\).</p>

<p>Now consider the reduced model obtained by averaging the observations 
in the same &quot;cell&quot; \((i,j)\):</p>

<p>\[({\cal M}')\colon \qquad
\bar y_{ij\bullet} \sim {\cal N}\left(\mu+\alpha_i+\beta_j, \frac{\sigma^2}{K}\right), \qquad i=1,\ldots,I, \quad j=1,\ldots,J.\]</p>

<p>The reduced model \({\cal M}'\) is  a fixed effects two-ways ANOVA model 
without interaction and without replications. 
We will consider for our illustration that \(I=2\), hence \(\alpha_2=-\alpha_1\), 
and we will compare the confidence intervals about \(\alpha_1\) obtained by 
considering either model \(\cal M\) or model \({\cal M}'\). </p>

<p>Let us simulate some data </p>

<pre><code class="r">I &lt;- 2 
J &lt;- 3
K &lt;- 4
effects1 &lt;- c(1,-1)
effects2 &lt;- 1:J - mean(1:J)
dat &lt;- data.frame(factor1=rep(1:I,each=J*K), factor2=rep(1:J,times=I*K))
set.seed(666)
dat &lt;- transform(dat, 
                 y=rnorm(I*J*K, effects1[factor1]+effects2[factor2]), 
                 factor1=factor(factor1), 
                 factor2=factor(factor2)
                 ) 
head(dat)
</code></pre>

<pre><code>##   factor1 factor2       y
## 1       1       1  0.7533
## 2       1       2  3.0144
## 3       1       3  1.6449
## 4       1       1  2.0282
## 5       1       2 -1.2169
## 6       1       3  2.7584
</code></pre>

<p>Fitting the model as follows, the parameter of interest \(\alpha_1=1\) is named <code>factor11</code> in R:</p>

<pre><code class="r">fit1 &lt;- lm(y~factor1+factor2,data=dat,contrasts=list(factor1=&quot;contr.sum&quot;,factor2=&quot;contr.sum&quot;))
pandoc.table(confint(fit1), style=&quot;rmarkdown&quot;, digits=3, emphasize.rows=2)
</code></pre>

<table><thead>
<tr>
<th align="center">&nbsp;</th>
<th align="center">2.5 %</th>
<th align="center">97.5 %</th>
</tr>
</thead><tbody>
<tr>
<td align="center"><strong>(Intercept)</strong></td>
<td align="center">-0.595</td>
<td align="center">0.521</td>
</tr>
<tr>
<td align="center"><strong>factor11</strong></td>
<td align="center"><em>0.43</em></td>
<td align="center"><em>1.55</em></td>
</tr>
<tr>
<td align="center"><strong>factor21</strong></td>
<td align="center">-1.7</td>
<td align="center">-0.116</td>
</tr>
<tr>
<td align="center"><strong>factor22</strong></td>
<td align="center">-0.46</td>
<td align="center">1.12</td>
</tr>
</tbody></table>

<p>Now we look at the confidence interval in the reducel model \({\cal M}'\):</p>

<pre><code class="r">mdat &lt;- aggregate(y~factor1+factor2, data=dat, FUN=mean)
fit2 &lt;- lm(y~factor1+factor2,data=mdat,contrasts=list(factor1=&quot;contr.sum&quot;,factor2=&quot;contr.sum&quot;))
pandoc.table(confint(fit2), style=&quot;rmarkdown&quot;, digits=3, emphasize.rows=2)
</code></pre>

<table><thead>
<tr>
<th align="center">&nbsp;</th>
<th align="center">2.5 %</th>
<th align="center">97.5 %</th>
</tr>
</thead><tbody>
<tr>
<td align="center"><strong>(Intercept)</strong></td>
<td align="center">-0.82</td>
<td align="center">0.746</td>
</tr>
<tr>
<td align="center"><strong>factor11</strong></td>
<td align="center"><em>0.206</em></td>
<td align="center"><em>1.77</em></td>
</tr>
<tr>
<td align="center"><strong>factor21</strong></td>
<td align="center">-2.01</td>
<td align="center">0.202</td>
</tr>
<tr>
<td align="center"><strong>factor22</strong></td>
<td align="center">-0.778</td>
<td align="center">1.44</td>
</tr>
</tbody></table>

<p>The confidence interval in \({\cal M}'\) is wider than the one in \(\cal M\). 
Let us use simulations to see this more precisely. 
Below we use simulations to derive the distributions of the upper bound 
of the confidence interval in \(\cal M\) and \({\cal M}'\). 
We use the <code>local</code> function to preserve our preliminary defined 
objects <code>dat</code>, <code>fit1</code>, and <code>fit2</code>. 
We also evaluate, for each model the power of the test for 
\(H_0\colon\{\alpha_1=0\}\) derived from the confidence interval.</p>

<pre><code class="r">nsims &lt;- 5000
confint1 &lt;- confint2 &lt;- NULL
power1 &lt;- power2 &lt;- rep(NA,nsims)
local({
  for(i in 1:nsims){
    # new data
    dat &lt;- within(dat, y &lt;- rnorm(I*J*K, effects1[factor1]+effects2[factor2])) 
    # model M
    fit1 &lt;- lm(y~factor1+factor2,data=dat,contrasts=list(factor1=&quot;contr.sum&quot;,factor2=&quot;contr.sum&quot;))
    ci &lt;- confint(fit1)[2,]
    power1[i] &lt;&lt;- ci[1]&gt;0 || ci[2]&lt;0
    confint1 &lt;&lt;- rbind(confint1,ci)
    # model M&#39;
    mdat &lt;- aggregate(y~factor1+factor2, data=dat, FUN=mean)
    fit2 &lt;- lm(y~factor1+factor2,data=mdat,contrasts=list(factor1=&quot;contr.sum&quot;,factor2=&quot;contr.sum&quot;))
    ci &lt;- confint(fit2)[2,]
    power2[i] &lt;&lt;- ci[1]&gt;0 || ci[2]&lt;0
    confint2 &lt;&lt;- rbind(confint2,ci)
    }
  })
plot(density(confint1[,2]), 
     main=&quot;Distribution of the upper bound of the confidence interval&quot;, 
     ylab=NA, xlab=NA, 
     axes=FALSE, col=&quot;blue&quot;,
     xlim=range(confint2[,2]))
lines(density(confint2[,2]), col=&quot;red&quot;)
alpha1 &lt;- effects1[1]
axis(1, at=alpha1, labels=expression(alpha[1]))
abline(v=alpha1, lty=&quot;dashed&quot;)
</code></pre>

<p><img src="assets/fig/ModelReductionunnamed-chunk-4.png" alt="plot of chunk unnamed-chunk-4"> </p>

<p>As we said in the previous section, the confidence interval derived from 
the reduced model \({\cal M}'\) is correct: for both curves, the area at the left 
of \(\alpha_1\) is \(2.5\%\). 
But the upper bound is considerably more dispersed for model \({\cal M}'\), 
thereby showing that the confidence interval  is more likely wider 
 for model \({\cal M}'\). </p>

<p>As a consequence, the power of the test of \(H_0\colon\{\alpha_1=0\}\) is higher 
for \(\cal M\):</p>

<pre><code class="r">mean(power1)
</code></pre>

<pre><code>## [1] 0.9954
</code></pre>

<pre><code class="r">mean(power2)
</code></pre>

<pre><code>## [1] 0.7116
</code></pre>

<p>Note that \(H_0\) means that the first factor has no effect, and actually it can 
be shown that the test based on the confidence interval is exactly the same 
as the classical Fisher test provided by the <code>anova</code> function:</p>

<pre><code class="r">anova(fit1)
</code></pre>

<pre><code>## Analysis of Variance Table
## 
## Response: y
##           Df Sum Sq Mean Sq F value Pr(&gt;F)   
## factor1    1   23.5   23.46   13.64 0.0014 **
## factor2    2   10.1    5.05    2.93 0.0763 . 
## Residuals 20   34.4    1.72                  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
</code></pre>

<pre><code class="r">anova(fit2)
</code></pre>

<pre><code>## Analysis of Variance Table
## 
## Response: y
##           Df Sum Sq Mean Sq F value Pr(&gt;F)  
## factor1    1   5.86    5.86   29.51  0.032 *
## factor2    2   2.52    1.26    6.35  0.136  
## Residuals  2   0.40    0.20                 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
</code></pre>

<p>We can understand why the power is suboptimal in \({\cal M}'\). 
As you know, the \(F\) statistic is the ratio of the mean square of 
factor \(1\) over the residual mean square. 
The residual sum of squares  in the 
decomposition of the variation provided by <code>anova(fit1)</code>:
\[ 
SS(y) = SS_A(y) + SS_B(y) + SS_{ {(1+A+B)}^\perp}(y)
\]
can be itself decomposed by including the interaction term, thereby 
yielding a new decomposition :
\[ 
SS(y) = SS_A(y) + SS_B(y) + SS_{AB} + SS_{ {(1+A+B+AB)}^\perp}(y)
\]
which is here:</p>

<pre><code class="r">anova(update(fit1, y~factor1*factor2)) 
</code></pre>

<pre><code>## Analysis of Variance Table
## 
## Response: y
##                 Df Sum Sq Mean Sq F value Pr(&gt;F)   
## factor1          1   23.5   23.46   12.87 0.0021 **
## factor2          2   10.1    5.05    2.77 0.0895 . 
## factor1:factor2  2    1.6    0.80    0.44 0.6531   
## Residuals       18   32.8    1.82                  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
</code></pre>

<p>The first three mean squares are exactly \(K=4\) times the sum of squares in 
\({\cal M}'\):</p>

<pre><code class="r">K*anova(fit2)[,2:3]
</code></pre>

<pre><code>##           Sum Sq Mean Sq
## factor1    23.46 23.4594
## factor2    10.09  5.0454
## Residuals   1.59  0.7951
</code></pre>

<p>Thus, we have the following equality about the classical Fisher statistic \(F'\) 
for \(H_0\colon\{\alpha_1=0\}\) in the reduced model \({\cal M}'\):
\[
F' := \frac{MS_A(z)}{MS_{ {(1+A+B)}^\perp}(z)} 
= \frac{MS_A(y)}{MS_{AB}(y)} 
\sim F_{I-1, (I-1)(J-1)}
\] 
whereas the  classical Fisher statistic \(F\) 
for \(H_0\colon\{\alpha_1=0\}\) in the unreduced model \({\cal M}\) is:
\[
F = \frac{MS_A(y)}{MS_{ {(1+A+B)}^\perp}(y)}
\sim F_{I-1, (I-1)(J-1) + IJ(K-1)}
\]
thereby showing that the reducel model \({\cal M}'\) yields a less 
powerful test. </p>

<h2>Why does it work for the random effects one-way ANOVA model ?</h2>

<p>Using the hierarchical writing of the model
\[\begin{cases}
 (y_{ij} \mid \mu_i) \sim_{\text{iid}} {\cal N}(\mu_i, \sigma^2_w) & j=1,\ldots,J \\ 
\mu_i \sim_{\text{iid}} {\cal N}(\mu, \sigma^2_b) & i=1,\ldots,I
\end{cases},\]
it is quite easy to write down the joint distribution of the \(y_{ij}\) and the \(\mu_i\). 
Setting \(\sigma^2=J\sigma^2_b+\sigma^2_w\) and integrating over the \(\mu_i\) yields the likelihood
\[
L\bigl(\mu, \sigma_b, \sigma_w \mid \{y_{ij}\}\bigr) \propto 
{(\sigma_w^2)}^{-\frac{I(J-1)}{2}}{(\sigma^2)}^{-\frac{I}{2}}
\exp\left[-\frac{1}{2}\left(
\frac{IJ{(\bar{y}_{\bullet\bullet}-\mu)}^2}{\sigma^2} + \frac{SS_b(y)}{\sigma^2} + \frac{SS_w(y)}{\sigma^2_w}
\right)\right],
\]
thereby showing that the triple of the three summary statistics 
\(\bigl\{\bar{y}_{\bullet\bullet}, SS_b(y), SS_w(y)\bigr\}\) is sufficient 
for \((\mu, \sigma_b, \sigma_w)\).</p>

<p>Moreover, because of the equality 
\[IJ{(\bar{y}_{\bullet\bullet}-\mu)}^2 + SS_b(y) 
= J\sum_{i=1}^I {(\bar{y}_{i\bullet}-\mu)}^2,\]
the likelihood can also be written 
\[
\begin{align}
L\bigl(\mu, \sigma_b, \sigma_w \mid \{y_{ij}\}\bigr) & \propto 
{(\sigma_w^2)}^{-\frac{I(J-1)}{2}}{(\sigma^2)}^{-\frac{I}{2}}
\exp\left[-\frac{1}{2}\left(
\frac{J\sum_{i=1}^I {(\bar{y}_{i\bullet}-\mu)}^2}{\sigma^2} + \frac{SS_w(y)}{\sigma^2_w}
\right)\right] \\ 
& \propto
\left({(\sigma_w^2)}^{-\frac{I(J-1)}{2}}
\exp\left[-\frac{1}{2}
 \frac{SS_w(y)}{\sigma^2_w}
\right]\right)
\left( 
{(\sigma^2)}^{-\frac{I}{2}}
\exp\left[-\frac{1}{2}
\frac{J\sum_{i=1}^I {(\bar{y}_{i\bullet}-\mu)}^2}{\sigma^2}
\right] 
\right).
\end{align}
\]</p>

<p>That shows that the group means \(\bar{y}_{i\bullet}\) are sufficient for 
\((\mu, \sigma)\). </p>

</div>
              <div id="disqus_thread"></div>
            </li>
          </ol>
          <div class="pagination">
            <ul>
              <li><a href="http://stla.github.com/stlapblog/">&#171; Back Home</a></li>
            </ul>
          </div> 
        </div>
			</div>
		</div>
  </div>
</body>
  <script src='../libraries/frameworks/purus/js/bootstrap.min.js'></script>
  <script>
      var disqus_developer = 1;
      var disqus_shortname = 'stlapblog'; 
      // required: replace example with your forum shortname
      /* * * DON'T EDIT BELOW THIS LINE * * */
      (function() {
          var dsq = document.createElement('script'); 
          dsq.type = 'text/javascript'; dsq.async = true;
          dsq.src = 'http://' + disqus_shortname + '.disqus.com/embed.js';
          (document.getElementsByTagName('head')[0] || 
           document.getElementsByTagName('body')[0]).appendChild(dsq);
      })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  <!-- MathJax: Fall back to local if CDN offline but local image fonts are not supported (saves >100MB) -->
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        processEscapes: true
      }
    });
  </script>
  <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/2.0-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  <!-- <script src="https://c328740.ssl.cf1.rackcdn.com/mathjax/2.0-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script> -->
  <script>window.MathJax || document.write('<script type="text/x-mathjax-config">MathJax.Hub.Config({"HTML-CSS":{imageFont:null}});<\/script><script src="../libraries/widgets/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"><\/script>')
</script>
<!-- Google Prettify -->
  <script src="http://cdnjs.cloudflare.com/ajax/libs/prettify/188.0.0/prettify.js"></script>
  <script src='../libraries/highlighters/prettify/js/lang-r.js'></script>
  <script>
    var pres = document.getElementsByTagName("pre");
    for (var i=0; i < pres.length; ++i) {
      pres[i].className = "prettyprint linenums";
    }
    prettyPrint();
  </script>
  <!-- End Google Prettify --> 
  </html>