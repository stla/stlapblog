<!DOCTYPE html>
<html>
<head>
  <title>Equivalence testing based on exceedance probabilities</title>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="" />
  <meta name="author" content="">
  <link rel="shortcut icon" href="assets/img/07-10-06_2241.jpg">
  <link rel="alternate" type="application/rss+xml" href="">
  <link href="../libraries/frameworks/purus/css/bootstrap.min.css" rel="stylesheet" />
  <link href="../libraries/frameworks/purus/css/bootstrap-responsive.min.css" rel="stylesheet" />
  <link href="../libraries/frameworks/purus/css/main.css" rel="stylesheet" />
  <link href="../libraries/highlighters/prettify/css/twitter-bootstrap.css" rel="stylesheet">
  <!-- IE6-8 support of HTML5 elements -->
  <!--[if lt IE 9]>
    <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
  <![endif]-->
  <link href='http://fonts.googleapis.com/css?family=Raleway:400,600,200,800' rel='stylesheet' type='text/css'>
  <link href='http://fonts.googleapis.com/css?family=Open+Sans' rel='stylesheet' type='text/css'>
  <link href='http://fonts.googleapis.com/css?family=Droid+Sans' rel='stylesheet' type='text/css'>
  <script src="http://ajax.googleapis.com/ajax/libs/jquery/1.8.3/jquery.min.js"></script>
    <style>
  	#disqus_thread {
		margin-top: 140px;
	}
	  #sidebar .sidebar-nav .info h3 a:hover, a:hover { color: #01A9DB; }
	  #sidebar .sidebar-nav #avatar img, #sidebar .sidebar-nav ul#links li.active a { border-color: #01A9DB; }
	  #sidebar .sidebar-nav ul#links li a:hover { background: #01A9DB; }
    p {text-align: justify;}
  </style>
  <link rel="stylesheet" href = "../assets/css/box_with_title.css">
<link rel="stylesheet" href = "../assets/css/custom.css">
<link rel="stylesheet" href = "../assets/css/ribbons.css">

</head>
<body>
	<div class="container-fluid">
		<div class="row-fluid">
			<div id="sidebar" class="span2">
			  <div class="sidebar-nav sidebar-nav-fixed">
				  <div class="info">
				    <p id="avatar"><a href="#"><img alt="Title" src="http://stla.github.com/stlapblog/assets/img/07-10-06_2241.jpg " style="width:250px" /></a></p>
				    <h3><a href="/">stlaPblog </a></h3>
					  <p class="description">a blog about Mathematics, R, Statistics, ...</p>
					</div>
					<ul id="links">
			        <li><a href="http://stla.github.com/stlapblog/index.html">Home</a></li>
        <li><a href="http://stla.github.com/stlapblog/about.html">About</a></li>
      
				  <br/>
				  <div style="padding-left: 5px;">
					<h3>Some links</h3>
					<h4>&#9654 R links</h4>
						<div style="padding-left: 5px;">
					    <ul>
					      <li><a href="http://github.com/ramnathv/poirot/"><u>Poirot</u></a>Reproducible Blogging with R Markdown</li>
			          <li><a href="http://slidify.org/"><u>Slidify</u></a>Reproducible html5 slides from R markdown</li>
			          <li><a href="http://www.r-bloggers.com/"><u>R-bloggers</u></a>Blog posts about R, contributed by R bloggers worldwide.</li>
					    </ul>
				    </div>
			    <br/>
			  	<h4>&#9654 Blogs</h4>
						<div style="padding-left: 5px;">
					    <ul>
					      <li><a href="http://stla.overblog.com/"><u>stla.overblog</u></a>My previous blog</li>
			          <li><a href="http://timelyportfolio.blogspot.be/"><u>Timely Portfolio</u>
			</a>A great blog about R, Javascript, and more</li>
					    </ul>
				    </div>
					</div>
			    </ul>
				</div>
			</div>
						<div id="content" class='span10'>
				<div id="post-wrapper">
          <ol id="posts">
            <li class="post">
              <h3>
                <a href="#">Equivalence testing based on exceedance probabilities</a>
              </h3>
              <span>2015-01-06</span><br/>
               <a class='label label-success' href='https://raw.github.com/stla/stlapblog/gh-pages/posts/EquivalenceExceedanceProbabilities.Rmd'>Source</a>
              <div class='lead'>
<p>Equivalence testing is usually done by assessing the deviation between two 
Gaussian means \(\mu_1\) and \(\mu_2\).<br>
An acceptable deviation \(\Delta\) between \(\mu_1\) and \(\mu_2\) has to be set by the user, and then equivalence is accepted if 
there is a statistical significant evidence that the deviation between \(\mu_1\) and \(\mu_2\) 
does not exceed \(\Delta\). </p>

<p><img width="40%" src="assets/fig/Eep-plot0-1.png" alt="plot of chunk plot0"> </p>

<p>In some cases issued from fields of research such as psychology or agronomy, setting 
the acceptable deviation \(\Delta\) should cause no problem for the expert: 
the psychologist has its own advice about which difference between the score means 
of two series of psychological tests is considered as expressive, and similarly 
the agronomist has its own advice about which difference between the weight means 
of two populations of fruits is considered as expressive, </p>

<p>For industrial processes, the mean is not always the more relevant characteristic. 
For instance, an upper specification limit (\(USL\)) is given and the relevant characteristic 
of the process is the out-of-specification probability (\(OOS\)), that is, the probability 
that the process generates some data beyond \(USL\). </p>

<p><img width="65%" src="assets/fig/Eep-plot1-1.png" alt="plot of chunk plot1"> </p>

<p>Some guidelines recommend to set the acceptable deviation \(\Delta\) between the means by 
thinking in terms of specification limits. This requires to take into account the 
variability of the two processes under study. Once \(USL\) is given, it is very 
more natural to set an acceptable deviation between the exceendance probabilities 
\(OOS_1\) and \(OOS_2\) rather than between the means \(\mu_1\) and \(\mu_2\). 
We achieve the development of this approach in this article, by providing a 
confidence interval about the difference \(OOS_1-OOS_2\) between the two exceedance 
probabilities. We give a Bayesian method in the case of independant samples with equal variances, which can be similarly applied to the case of unequal variances and 
to the case of paired samples. 
Our methods are easily modified 
to handle the case of a lower specification limit as well as the case  of a 
specification two-sided interval. </p>

<h2>Jeffreys posterior distribution for the ANOVA model</h2>

<p>We assume two independent Gaussian sampling distributions sharing the same variance, that is, a one-way ANOVA model with two groups. We will perform statistical inference based on a noninformative Bayesian approach.  The <code>banova</code> function below generates the Jeffreys posterior distribution of the parameters.</p>

<pre><code class="r">&gt; banova &lt;- function(y, group, nsims=100000){
+   group &lt;- factor(group)
+   means &lt;- aggregate(y~group, FUN=mean)$y # groups means
+   sizes &lt;- table(group) # groups sizes
+   ssq &lt;- crossprod(y-rep(means, times=sizes)) # residual sum of squares
+   sigma &lt;- sqrt(ssq/rchisq(nsims,df=length(y)))
+   mu &lt;- lapply(structure(1:nlevels(group), names=levels(group)),
+                function(i) rnorm(nsims, means[i], sigma/sqrt(sizes[i])))
+   return(data.frame(mu, sigma=sigma))
+ }
</code></pre>

<p>The model has three parameters \(\mu_1\), \(\mu_2\) and \(\sigma\) and their posterior simulations are stored in a data frame. Let us see an example with a simulated balanced dataset with \(20\) observations in each group:</p>

<pre><code class="r">&gt; I &lt;- 2 # number of groups
&gt; J &lt;- 20 # number of replicates per group
&gt; mu &lt;- c(2,2.5) # group means
&gt; sigma &lt;- 1 # standard deviation within each group
&gt; group &lt;- gl(I, J, labels=sprintf(&quot;group%s&quot;, 1:I)) # groups
&gt; set.seed(666)
&gt; y &lt;- c(sapply(mu, function(mu) rnorm(J, mu, sigma))) # response
</code></pre>

<p>The theoretical model is given by this picture:</p>

<p><img width="40%" src="assets/fig/Eep-plot3-1.png" alt="plot of chunk plot3"> </p>

<p>The <code>banova</code> function takes a short time to generate \(10^6\) samples of the posterior distribution:</p>

<pre><code class="r">&gt; system.time(sims &lt;- banova(y, group, nsims = 1e+06))
   user  system elapsed 
  0.602   0.025   0.626 
&gt; head(sims,3)
</code></pre>

<table><thead>
<tr>
<th align="right">group1</th>
<th align="right">group2</th>
<th align="right">sigma</th>
</tr>
</thead><tbody>
<tr>
<td align="right">1.905582</td>
<td align="right">2.146182</td>
<td align="right">1.099777</td>
</tr>
<tr>
<td align="right">1.836148</td>
<td align="right">2.097849</td>
<td align="right">1.259851</td>
</tr>
<tr>
<td align="right">1.773983</td>
<td align="right">2.618615</td>
<td align="right">1.103276</td>
</tr>
</tbody></table>

<h2>Frequentist matching property</h2>

<p>An appealing property of the Jeffreys posterior distribution is the so-called <em>frequentist matching property</em>. That means that the posterior \(100(1-\alpha)\%\)-credibility intervals of a parameter of interest approximately have a \(100(1-\alpha)\%\) frequentist coverage. This is not true in general for any model, and this is not true for any parameter of interest, but say it is expected to be true in general.</p>

<p>Here for example, this is true for the group means \(\mu_1\) and \(\mu_2\). They have a tractable posterior distribution, each of them follows a  scaled Student distribution centered around the least-squares estimates. Thus, the posterior means coincide with the least-square estimates:</p>

<pre><code class="r">&gt; names(sims)[1:2] &lt;- c(&quot;µ1&quot;, &quot;µ2&quot;)
&gt; sapply(sims, mean)
      µ1       µ2    sigma 
2.001408 2.246180 1.197806 
&gt; fit &lt;- lm(y~0+group)
&gt; coef(fit)
groupgroup1 groupgroup2 
   2.001438    2.246584 
</code></pre>

<p>Equi-tailed posterior credibility intervals are obtained by taking the quantiles of the posterior distributions:</p>

<pre><code class="r">&gt; sapply(sims, function(x) quantile(x, c(2.5, 97.5)/100))
</code></pre>

<table><thead>
<tr>
<th align="left"></th>
<th align="right">µ1</th>
<th align="right">µ2</th>
<th align="right">sigma</th>
</tr>
</thead><tbody>
<tr>
<td align="left">2.5%</td>
<td align="right">1.470561</td>
<td align="right">1.715085</td>
<td align="right">0.9649394</td>
</tr>
<tr>
<td align="left">97.5%</td>
<td align="right">2.532203</td>
<td align="right">2.776631</td>
<td align="right">1.5032790</td>
</tr>
</tbody></table>

<p>We can get them without using the simulations with the help of the Student quantiles:</p>

<pre><code class="r">&gt; S2 &lt;- crossprod(residuals(fit)) # sum of squares
&gt; freqs &lt;- sapply(unique(group), function(label) length(which(group==label))) # group sizes
&gt; n &lt;- sum(freqs)
&gt; indexes &lt;- setNames(1:I, paste0(&quot;µ&quot;, 1:I))
&gt; vapply(indexes, function(i) coef(fit)[i] + sqrt(S2/(n*freqs[i]))*qt(c(2.5, 97.5)/100, n), FUN.VALUE=numeric(2))
</code></pre>

<table><thead>
<tr>
<th align="right">µ1</th>
<th align="right">µ2</th>
</tr>
</thead><tbody>
<tr>
<td align="right">1.470352</td>
<td align="right">1.715497</td>
</tr>
<tr>
<td align="right">2.532525</td>
<td align="right">2.777670</td>
</tr>
</tbody></table>

<p>This formula of the interval limits is close to the one giving the classical confidence interval (provided by <code>confint(fit)</code>):</p>

<pre><code class="r">&gt; vapply(indexes, function(i) coef(fit)[i] + sqrt(S2/(freqs[i]*(n-I)))*qt(c(2.5, 97.5)/100, n-I), FUN.VALUE=numeric(2))
</code></pre>

<table><thead>
<tr>
<th align="right">µ1</th>
<th align="right">µ2</th>
</tr>
</thead><tbody>
<tr>
<td align="right">1.455661</td>
<td align="right">1.700806</td>
</tr>
<tr>
<td align="right">2.547216</td>
<td align="right">2.792362</td>
</tr>
</tbody></table>

<p>The frequentist interval is a bit wider, and the difference disappears as \(n\) increase.</p>

<h2>Comparing the OOS</h2>

<p>Something very cool with the posterior simulations is the straightforward way to get posterior simulations of any quantity of interest \(\theta=f(\mu_1, \mu_2, \sigma)\) by simply applying the function \(f\) to the posterior simulations of \((\mu_1, \mu_2, \sigma)\). 
Here we are interested in the difference between \(OOS_1\) and \(OOS_2\), the probabilities to get an observation above \(USL\) in twe two groups, for a given upper specification limit \(USL\). The first one is \(1-\Phi\left(\frac{USL-\mu_1}{\sigma}\right)\) and the second one is  \(1-\Phi\left(\frac{USL-\mu_2}{\sigma}\right)\), thus we get the credibility intervals as follows, taking \(USL=4\):</p>

<pre><code class="r">&gt; library(dplyr) 
&gt; USL &lt;- 4
&gt; sims1 &lt;- mutate(sims, OOS1 = 100*(1-pnorm(USL, µ1, sigma)), OOS2 = 100*(1-pnorm(USL, µ2, sigma)), Delta=OOS2-OOS1)
&gt; kable(sims1 %&gt;% reshape2::melt() %&gt;% group_by(variable) %&gt;% summarise(estimate=mean(value), lwr=quantile(value, 2.5/100), upr=quantile(value, 97.5/100)), digits=2, caption=&quot;Jeffreys estimates and $95\\%$-credibility intervals&quot;)
</code></pre>

<table><thead>
<tr>
<th align="left">variable</th>
<th align="right">estimate</th>
<th align="right">lwr</th>
<th align="right">upr</th>
</tr>
</thead><tbody>
<tr>
<td align="left">µ1</td>
<td align="right">2.00</td>
<td align="right">1.47</td>
<td align="right">2.53</td>
</tr>
<tr>
<td align="left">µ2</td>
<td align="right">2.25</td>
<td align="right">1.72</td>
<td align="right">2.78</td>
</tr>
<tr>
<td align="left">sigma</td>
<td align="right">1.20</td>
<td align="right">0.96</td>
<td align="right">1.50</td>
</tr>
<tr>
<td align="left">OOS1</td>
<td align="right">5.24</td>
<td align="right">1.16</td>
<td align="right">13.14</td>
</tr>
<tr>
<td align="left">OOS2</td>
<td align="right">7.65</td>
<td align="right">2.11</td>
<td align="right">17.32</td>
</tr>
<tr>
<td align="left">Delta</td>
<td align="right">2.41</td>
<td align="right">-5.33</td>
<td align="right">11.36</td>
</tr>
</tbody></table>

<p>Note that the intervals around \(OOS_1\), \(OOS_2\) and \(\Delta\) are quite large. That shows that the estimates are far to be precise. </p>

<p><strong>(R point) The pipe operator <code>%&gt;%</code>.</strong> As you see, I used the <code>%&gt;%</code> operator in the previous code block. This operator is provided by the <code>magrittr</code> package, which is automatically loaded here by loading the <code>dplyr</code> package. 
In case you don&#39;t know this operator, I will explain a shorter example in the next section. Here we use it in order to avoid to nest too many functions : <code>summarise(group_by(reshape2::melt(sims1, ...</code>. </p>

<h2>Looking at the deviation in function of \(USL\)</h2>

<p>It is interesting to look at the \(OOS\) deviation in function of \(USL\). For our example, here is the theoretical picture:</p>

<p><img width="72%" src="assets/fig/Eep-dev_vs_usl-1.png" alt="plot of chunk dev_vs_usl"> </p>

<p>The maximal value of the \(OOS\) deviation \(\Delta\) is called the <em>Kolmogorov distance</em> between the two distributions. In our case of two Gaussian distributions with equal variances, it is attained for \(USL=\dfrac{\mu_1+\mu_2}{2\sigma}\) (see the derivation in the Appendix), and shown by the orange line on the figure. </p>

<p>Thus, we could derive an estimate and a credibility interval around the Kolmogorov distance, that is to say the maximal deviation between \(OOS_1\) and  \(OOS_2\) over all possible values of \(USL\):</p>

<pre><code class="r">&gt; Kdist &lt;- function(µ1, µ2, sigma) ((µ1+µ2)/2/sigma) %&gt;% {pnorm(., µ1, sigma) - pnorm(., µ2, sigma)} %&gt;% abs
&gt; Kdist_sims &lt;- with(sims, 100*Kdist(µ1, µ2, sigma))mean(Kdist_sims); quantile(Kdist_sims, probs = c(2.5,97.5)/100)
[1] 11.54142
      2.5%      97.5% 
 0.4700835 31.1350492 
</code></pre>

<p>But this is not really releveant in the context of \(OOS\). It is clear on our example where \(\sigma=1\) that we are not interested in the deviation \(\Delta\) for a value of \(USL\) such as \(USL=\dfrac{\mu_1+\mu_2}{2\sigma}\). In practice the value of \(USL\) is usually located in the upper tails of the two Gaussian distributions. </p>

<p><strong>(R point) The pipe operator <code>%&gt;%</code>.</strong> As promised, I detail an example of the use of the <code>%&gt;%</code> operator.  Without this operator, I would have defined the <code>Kdist</code> function as follows:</p>

<pre><code class="r">&gt; Kdist &lt;- function(µ1, µ2, sigma) abs(pnorm((µ1+µ2)/2/sigma, µ1, sigma) - pnorm((µ1+µ2)/2/sigma, µ2, sigma))
</code></pre>

<p>or, in order to avoid the double calculation of <code>(µ1+µ2)/2/sigma</code>:</p>

<pre><code class="r">&gt; Kdist &lt;- function(µ1, µ2, sigma){
+   x &lt;- (µ1+µ2)/2/sigma
+   abs(pnorm(x, µ1, sigma) - pnorm(x, µ2, sigma))
+ }
</code></pre>

<p>Here, the pipe operator <code>%&gt;%</code> firstly allows up to map <code>(µ1+µ2)/2/sigma</code> conveniently:</p>

<pre><code class="r">&gt; ((µ1+µ2)/2/sigma) %&gt;% {pnorm(., µ1, sigma) - pnorm(., µ2, sigma)}
</code></pre>

<p>Then the result is mapped to the <code>abs</code> function by adding <code>%&gt;% abs</code> (equivalently <code>%&gt;% abs(.)</code>), instead of encapsulating the result by doing <code>abs(...)</code>. </p>

<p>Now we calculate and plot the estimate of \(\Delta\) and its credibility interval in function of \(USL\). </p>

<pre><code class="r">&gt; library(tidyr) # to use spread()
&gt; sims &lt;- reshape2::melt(data.frame(id=1:nrow(sims), sims), id.vars=c(&quot;id&quot;, &quot;sigma&quot;), value.name=&quot;µ&quot;, variable.name=&quot;group&quot;)
&gt; levels(sims$group) &lt;- c(&quot;group1&quot;, &quot;group2&quot;)
&gt; head(sims, 3)
</code></pre>

<table><thead>
<tr>
<th align="right">id</th>
<th align="right">sigma</th>
<th align="left">group</th>
<th align="right">µ</th>
</tr>
</thead><tbody>
<tr>
<td align="right">1</td>
<td align="right">1.099777</td>
<td align="left">group1</td>
<td align="right">1.905582</td>
</tr>
<tr>
<td align="right">2</td>
<td align="right">1.259851</td>
<td align="left">group1</td>
<td align="right">1.836148</td>
</tr>
<tr>
<td align="right">3</td>
<td align="right">1.103276</td>
<td align="left">group1</td>
<td align="right">1.773983</td>
</tr>
</tbody></table>

<pre><code class="r">&gt; usl &lt;- seq(0,5, by=0.25)
&gt; sims &lt;- cbind(USL=usl, 
+               data.frame(sims[,c(&quot;id&quot;,&quot;group&quot;)], setNames(lapply(usl, function(USL) 100*(1-pnorm(USL, sims$µ, sims$sigma))), paste0(&quot;OOS_&quot;, usl))) %&gt;% 
+                 reshape2::melt(id.vars=c(&quot;group&quot;,&quot;id&quot;)) %&gt;% spread(group, value) %&gt;% 
+                 mutate(Delta=group2-group1) %&gt;% 
+                 group_by(variable) %&gt;% 
+                 summarise(estimate=mean(Delta), 
+                           lwr=quantile(Delta, 2.5/100), 
+                           upr=quantile(Delta, 97.5/100)))[,-2]
&gt; head(sims,3)
</code></pre>

<table><thead>
<tr>
<th align="right">USL</th>
<th align="right">estimate</th>
<th align="right">lwr</th>
<th align="right">upr</th>
</tr>
</thead><tbody>
<tr>
<td align="right">0.00</td>
<td align="right">1.741791</td>
<td align="right">-3.967600</td>
<td align="right">8.705849</td>
</tr>
<tr>
<td align="right">0.25</td>
<td align="right">2.421491</td>
<td align="right">-5.345896</td>
<td align="right">11.412120</td>
</tr>
<tr>
<td align="right">0.50</td>
<td align="right">3.244611</td>
<td align="right">-6.983556</td>
<td align="right">14.542463</td>
</tr>
</tbody></table>

<pre><code class="r">&gt; library(ggplot2)
&gt; ggplot(sims, aes(x=USL,y=estimate)) + geom_line() +
+   geom_ribbon(aes(ymin=lwr, ymax=upr), alpha=0.1) +
+   ylab(expression(Delta)) + 
+   stat_function(fun=function(USL) 100*(pnorm(USL, mu[1], sigma)-pnorm(USL, mu[2], sigma)), color=&quot;red&quot;)
</code></pre>

<p><img src="assets/fig/Eep-interval_dev_vs_usl-1.png" alt="plot of chunk interval_dev_vs_usl"> </p>

<p>The theoretical deviation is shown by the red curve, the estimated deviation is shown by the black curve. We still note how large are the credibility intervals, especially around the maximual value of the deviation.</p>

<h2>Appendix: Kolmogorov distance between two Gaussian distributions</h2>

<p>Our purpose is to give an expression for the Kolmogorov distance \(K(\mu_1,\sigma_1,\mu_2,\sigma_2)\) between the two Gaussian distributions  \({\cal N}(\mu_1, \sigma_1^2)\) and \({\cal N}(\mu_2, \sigma_2^2)\), defined by
 \[K(\mu_1,\sigma_1,\mu_2,\sigma_2) = \sup_{t \in \mathbb{R}} \bigl|\Pr(X \leq t) - \Pr(Y \leq t) \bigr|\] with \(X \sim {\cal N}(\mu_1, \sigma_1^2)\) and \(Y \sim {\cal N}(\mu_2, \sigma_2^2)\).</p>

<p>Writing 
\[\Pr(X \leq t) - \Pr(Y \leq t) = \Pr\left(\frac{X-\mu_1}{\sigma_1} \leq \frac{t-\mu_1}{\sigma_1}\right) - \Pr\left(\frac{Y-\mu_2}{\sigma_2} \leq \frac{t-\mu_2}{\sigma_2}\right),\]
the expression we are looking for is obtained from the expression of 
 \[\sup_{z \in \mathbb{R}} \bigl|\Pr(Z_1 \leq z) - \Pr(Z_2 \leq az+b) \bigr|\] with \(Z_1, Z_2 \sim {\cal N}(0, 1)\) and \(a>0\), by setting \(a=\frac{\sigma_1}{\sigma_2}\) and \(b=\frac{\mu_1-\mu_2}{\sigma_2}\). 
 Thus 
 \[K(\mu_1,\sigma_1,\mu_2,\sigma_2) = \sup_{z \in \mathbb{R}} \bigl|\Psi_{a,b}(z) \bigr|\] 
 where \(\Psi_{a,b}\) is the function defined by 
  \[\Psi_{a,b}(z)= \Phi(z) - \Phi(az+b)\] 
for the values of \(a\) and \(b\) given above. By symmetry one can also take \(a=\frac{\sigma_2}{\sigma_1}\) and \(b=\frac{\mu_2-\mu_1}{\sigma_1}\), and then it suffices to focus on the case \(b \geq 0\). </p>

<p>By elementary calculus, the derivative of \(\Psi_{a,b}\) is given by 
\[
{\Psi'}_{a,b}(z) =\frac{e^{-\frac{1}{2}z^2}-a e^{-\frac{1}{2} (b+a z)^2}}{\sqrt{2 \pi }}. 
\]
Discarding the trivial case \(a=1\) and \(b=0\), then \({\Psi_{1,b}}'(z)\) has a unique root at \(z=-\frac{b}{2}\), and if \(a\neq 1\) then \({\Psi_{a,b}}'(z)\) has two roots at 
\[ z_i= \frac{a b + {(-1)}^i \sqrt{b^2 + 2 (a^2-1) \log(a)}}{1-a^2}, \qquad i=1,2,\]
which we also write 
\[z_i = M + {(-1)}^i \Delta\] 
where \(M=\frac{a b}{1-a^2}\) and \(\Delta=\frac{\sqrt{b^2 + 2 (a^2-1) \log(a)}}{1-a^2}\). </p>

<p>Now we assume \(0 < a < 1\) and \(b \geq 0\), hence one has \(0 \leq M \leq \frac{b}{1-a}\) and \(\Delta>0\). Obviously \(z_2>0\) and it is not hard to see that \(z_1<0\).<br>
Furthermore, note that 
\[(az_i+b) -z_i =
\frac{b}{1+a} + {(-1)}^{i-1} (1-a)\Delta,\] 
hence  \((az_1+b) -z_1 >0\), and note that 
\[\bigl((az_1+b) -z_1\bigr)\bigl((az_2+b) -z_2\bigr)=\frac{2 (1-a)\log(a)}{1+a} < 0,\]
therefore  \((az_2+b) - z_2 < 0\). 
Finally, in the case when \(0 < a < 1\) and \(b \geq 0\), one has 
\(z_1 < 0 \leq M \leq \frac{b}{1-a} < z_2\) and we will now consider the two situations shown by these figures:</p>

<p><img width="45%" src="assets/fig/Eep-kplot1-1.png" alt="plot of chunk kplot1"> 
<img width="45%" src="assets/fig/Eep-kplot2-1.png" alt="plot of chunk kplot2"> </p>

<p>We will show that the supremum of \(\bigl|\Psi_{a,b}\bigr|\) is attained at \(z_1\) in both cases. 
Note that \(\bigl|\Psi_{a,b}(z_1)\bigr|=\Psi_{a,b}(z_1)\) is the standard Gaussian measure of the interval \(I_1=[z_1, az_1+b]\) and  \(\bigl|\Psi_{a,b}(z_2)\bigr|=-\Psi_{a,b}(z_2)\) is the standard Gaussian measure of the interval \(I_2=[az_2+b, z_2]\). The length of \(I_1\) is always larger than the one of \(I_2\). If \(az_1+b \geq 0\) (case \(1\)), then \(I_1\) contains \(0\), and then it is clear that the standard Gaussian measure of \(I_1\) is larger than the one of \(I_2\) in this case. If \(az_1+b < 0\) (case \(2\)), then one has \(|az_1+b| < az_2+b\) because of the equality 
\[(az_1+b)+(az_2+b)=\frac{b}{a^2-1} \geq 0,\]
which is easy to get by elementary calculus. Therefore the  standard Gaussian measure of \(I_1\)  is larger than the one of \(I_2\) also in case \(2\). </p>

<p>By doing similar considerations, the  case \(a > 1\) and \(b \geq 0\) is summarized by the two 
figures below, and we show by the same approach that  the supremum of \(\bigl|\Psi_{a,b}\bigr|\) is attained at \(z_1\). </p>

<p><img width="45%" src="assets/fig/Eep-kplot_ag1-1.png" alt="plot of chunk kplot_ag1"> 
<img width="45%" src="assets/fig/Eep-kplot_ag2-1.png" alt="plot of chunk kplot_ag2"> </p>

<p>The R function <code>Kdist</code> below returns the Kolmogorov distance:</p>

<pre><code class="r">Kdist00 &lt;-  function(a,b){
  z &lt;- (a * b - sign(b) * sqrt(b^2 + 2 * (a^2 - 1) * log(a)))/(1 - a^2)
  out &lt;- pnorm(a*z+b)-pnorm(z)
  attr(out, &quot;where&quot;) &lt;- z
  return(out)
}
Kdist0 &lt;- function(mu1,sigma1,mu2,sigma2){
  b &lt;- (mu1-mu2)/sigma2
  a &lt;- sigma1/sigma2
  if(b&gt;=0){
    out &lt;- Kdist00(a,b) 
    attr(out, &quot;where&quot;) &lt;- mu1 + sigma1*attr(out, &quot;where&quot;)
    return(out)
  }else{
    return(Kdist0(mu2,sigma2,mu1,sigma1))
  }
}
Kdist &lt;- function(mu1,sigma1,mu2,sigma2){
  if(sigma1==sigma2){
    where &lt;- -(mu1-mu2)/sigma2/2
    out &lt;-  abs(pnorm(where)-pnorm(-where))
    attr(out, &quot;where&quot;) &lt;- where
    return(out)
  }
  return(Kdist0(mu1,sigma1,mu2,sigma2))
}
</code></pre>

</div>
              <div id="disqus_thread"></div>
            </li>
          </ol>
          <div class="pagination">
            <ul>
              <li><a href="http://stla.github.com/stlapblog/">&#171; Back Home</a></li>
            </ul>
          </div> 
        </div>
			</div>
		</div>
  </div>
</body>
  <script src='../libraries/frameworks/purus/js/bootstrap.min.js'></script>
  <script>
      var disqus_developer = 1;
      var disqus_shortname = 'stlapblog'; 
      // required: replace example with your forum shortname
      /* * * DON'T EDIT BELOW THIS LINE * * */
      (function() {
          var dsq = document.createElement('script'); 
          dsq.type = 'text/javascript'; dsq.async = true;
          dsq.src = 'http://' + disqus_shortname + '.disqus.com/embed.js';
          (document.getElementsByTagName('head')[0] || 
           document.getElementsByTagName('body')[0]).appendChild(dsq);
      })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  <!-- MathJax: Fall back to local if CDN offline but local image fonts are not supported (saves >100MB) -->
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        processEscapes: true
      }
    });
  </script>
  <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/2.0-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  <!-- <script src="https://c328740.ssl.cf1.rackcdn.com/mathjax/2.0-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script> -->
  <script>window.MathJax || document.write('<script type="text/x-mathjax-config">MathJax.Hub.Config({"HTML-CSS":{imageFont:null}});<\/script><script src="../libraries/widgets/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"><\/script>')
</script>
<!-- Google Prettify -->
  <script src="http://cdnjs.cloudflare.com/ajax/libs/prettify/188.0.0/prettify.js"></script>
  <script src='../libraries/highlighters/prettify/js/lang-r.js'></script>
  <script>
    var pres = document.getElementsByTagName("pre");
    for (var i=0; i < pres.length; ++i) {
      pres[i].className = "prettyprint linenums";
    }
    prettyPrint();
  </script>
  <!-- End Google Prettify --> 
  </html>